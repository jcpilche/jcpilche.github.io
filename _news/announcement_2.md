---
layout: post
title: A long announcement with details
date: 2024-05-02 16:11:00-0400
inline: false
related_posts: false
---

I finalized my undergraduate thesis, 'Can We Use Language Models To Study Humans? Quantifying the Similarity Between Politically Opinionated LLMs and Humans'.

---

Abstract:
Studies that use agent based simulations to learn more about topics within human society, with a monotone society of agents, have received the critique that they can't be realistic or applied due to their misrepresentation of a diverse human population. This study looks at the possibility of using prompt-engineered language models to more closely replicate a vast range of humans for agent based models, creating a more realistic group of agents that can draw more definite conclusions for social science researchers who use this method of experimentation. We create a population of politically opinionated language models by prompting them to be at a certain level on the US political scale. To these politically opinionated LLMs, we replicate a sample of an election survey done on humans and compare the responses between humans and LLMs of the same political leaning to see if they adopt a similar array of beliefs. Our results show mediocre support for the ability to represent American political opinion with LLMs, as they often capture the stereotypical response of a political leaning but not the variance observed in the human political spectrum.
